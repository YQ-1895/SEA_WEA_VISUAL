{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processed 369 records\n",
      "âœ… Data saved to processed_reservoir_data.json\n",
      "ðŸ“Š Summary: 188 critical reservoirs, 262 critical hydropower stations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15330\\AppData\\Local\\Temp\\ipykernel_23720\\4001473938.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['is_critical_reservoir'] = df['max_capacity_mcm'].fillna(0) > 100\n",
      "C:\\Users\\15330\\AppData\\Local\\Temp\\ipykernel_23720\\4001473938.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['is_critical_hydropower'] = df['power_mw'].fillna(0) > 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def process_reservoir_data(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process reservoir data for the dashboard app\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Replace -999.9 with None and handle NaN values\n",
    "    df = df.replace(-999.9, None)\n",
    "    df = df.replace(-99, None)\n",
    "    \n",
    "    # Convert NaN to None for proper JSON serialization\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    # Clean and validate coordinates\n",
    "    df = df.dropna(subset=['longitude', 'latitude'])\n",
    "    df = df[(df['longitude'] >= -180) & (df['longitude'] <= 180)]\n",
    "    df = df[(df['latitude'] >= -90) & (df['latitude'] <= 90)]\n",
    "    \n",
    "    # Add classification categories\n",
    "    df['is_critical_reservoir'] = df['max_capacity_mcm'].fillna(0) > 100\n",
    "    df['is_critical_hydropower'] = df['power_mw'].fillna(0) > 30\n",
    "    \n",
    "    # Add capacity categories for visualization\n",
    "    def get_capacity_category(capacity):\n",
    "        if pd.isna(capacity) or capacity <= 0:\n",
    "            return 'Unknown'\n",
    "        elif capacity <= 10:\n",
    "            return '0-10MCM'\n",
    "        elif capacity <= 100:\n",
    "            return '10-100MCM'\n",
    "        elif capacity <= 1000:\n",
    "            return '100-1000MCM'\n",
    "        else:\n",
    "            return '>1000MCM'\n",
    "    \n",
    "    def get_power_category(power):\n",
    "        if pd.isna(power) or power <= 0:\n",
    "            return 'Unknown'\n",
    "        elif power <= 30:\n",
    "            return '0-30MW'\n",
    "        elif power <= 100:\n",
    "            return '30-100MW'\n",
    "        elif power <= 1000:\n",
    "            return '100-1000MW'\n",
    "        else:\n",
    "            return '>1000MW'\n",
    "    \n",
    "    df['capacity_category'] = df['max_capacity_mcm'].apply(get_capacity_category)\n",
    "    df['power_category'] = df['power_mw'].apply(get_power_category)\n",
    "    \n",
    "    # Create summary statistics\n",
    "    summary = {\n",
    "        'total_count': len(df),\n",
    "        'countries': df['country'].value_counts().to_dict(),\n",
    "        'main_uses': df['main_use'].value_counts().to_dict(),\n",
    "        'capacity_distribution': df['capacity_category'].value_counts().to_dict(),\n",
    "        'power_distribution': df['power_category'].value_counts().to_dict(),\n",
    "        'critical_reservoirs': int(df['is_critical_reservoir'].sum()),\n",
    "        'critical_hydropower': int(df['is_critical_hydropower'].sum())\n",
    "    }\n",
    "    \n",
    "    # Prepare final dataset\n",
    "    processed_data = {\n",
    "        'features': df.to_dict('records'),\n",
    "        'summary': summary,\n",
    "        'metadata': {\n",
    "            'total_records': len(df),\n",
    "            'last_updated': pd.Timestamp.now().isoformat(),\n",
    "            'filters': {\n",
    "                'countries': sorted(df['country'].dropna().unique().tolist()),\n",
    "                'main_uses': sorted(df['main_use'].dropna().unique().tolist()),\n",
    "                'commission_years': {\n",
    "                    'min': int(df['commission_year'].min()) if not df['commission_year'].isna().all() else None,\n",
    "                    'max': int(df['commission_year'].max()) if not df['commission_year'].isna().all() else None\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def clean_nans(obj):\n",
    "        \"\"\"\n",
    "        Recursively convert all NaN, inf, -inf to None for JSON safety\n",
    "        \"\"\"\n",
    "        if isinstance(obj, float):\n",
    "            if math.isnan(obj) or math.isinf(obj):\n",
    "                return None\n",
    "            return obj\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: clean_nans(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [clean_nans(v) for v in obj]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Clean processed_data recursively\n",
    "    safe_data = clean_nans(processed_data)\n",
    "\n",
    "    # Strict JSON output (disallow NaN)\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(safe_data, f, indent=2, allow_nan=False)\n",
    "\n",
    "    # print(f\"âœ… JSON cleaned and saved safely to {output_file}\")\n",
    "    \n",
    "    print(f\"âœ… Processed {len(df)} records\")\n",
    "    print(f\"âœ… Data saved to {output_file}\")\n",
    "    print(f\"ðŸ“Š Summary: {summary['critical_reservoirs']} critical reservoirs, {summary['critical_hydropower']} critical hydropower stations\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the data\n",
    "    result = process_reservoir_data(\n",
    "        # input_file='14-reservoirs_30MW_and_100MCM.csv',\n",
    "        input_file='13-allData_addSEAWEA_ID.csv',\n",
    "        output_file='processed_reservoir_data.json'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
